{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCFKRWGv-8t-",
        "outputId": "33e5e7ae-cb7c-4aaa-b80e-1c9ccf391d63"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.10.5 64-bit' requires ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/NITRO 5/AppData/Local/Programs/Python/Python310/python.exe\" -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "%cd MyDrive\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iIkcso6d_KN3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dmkfsklfmskl\n"
          ]
        }
      ],
      "source": [
        "# !git clone https://github.com/tobran/DF-GAN\n",
        "print(\"dmkfsklfmskl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yp_nTK9I_Ken",
        "outputId": "15b3dc82-f4b1-445a-e23a-14024a71ade7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/DF-GAN\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/MyDrive/DF-GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRO_yDqu__Hj",
        "outputId": "46a230f9-c80d-4d01-fdcf-3ba3763398c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "code  framework.png  README.md\t       selected_samples.jpg\n",
            "data  LICENSE.md     requirements.txt\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lWBcV-eAPuc",
        "outputId": "3c7bbcc9-4fd7-4312-dacc-834e002de7f2"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.10.5 64-bit' requires ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/NITRO 5/AppData/Local/Programs/Python/Python310/python.exe\" -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import traceback\n",
        "!pip install -r requirements.txt\n",
        "!pip install -U PyYAML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQktfQBIAP69",
        "outputId": "9b03074d-1941-4ef3-d66d-4b339c360f9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/DF-GAN/code\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/MyDrive/DF-GAN/code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOGkBOf0AP9m",
        "outputId": "b413ac47-cd47-4490-ab9e-b23eab7aec8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cfg   example_captions\tlib   models   saved_models  src\n",
            "eval  imgs\t\tlogs  samples  scripts\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3QWtZ5O_Wkw"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynAvliCJ_XmR",
        "outputId": "a71ce136-31f5-43e6-d011-1a2891737126"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load from:  ../data/birds/captions_DAMSM.pickle\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/inception.py:47: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Load ./saved_models/bird/pretrained/state_epoch_1220.pth for NetG\n",
            "************ Start sampling ************\n",
            "****************************************\n",
            "  0% 0/27 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:69: UserWarning: The parameter 'range' is deprecated since 0.12 and will be removed in 0.14. Please use 'value_range' instead.\n",
            "  \"The parameter 'range' is deprecated since 0.12 and will be removed in 0.14. \"\n",
            "100% 27/27 [00:20<00:00,  1.33it/s]\n",
            "****************************************\n",
            "Sampling done, 21.71s cost, saved to ./samples/bird/2022_11_08_05_44_53\n",
            "****************************************\n"
          ]
        }
      ],
      "source": [
        "!bash scripts/sample.sh ./cfg/bird.yml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SbMFnBNAQBA",
        "outputId": "69ad8234-5ad5-403a-853d-6214569c1a14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py:186: FutureWarning: The module torch.distributed.launch is deprecated\n",
            "and will be removed in future. Use torchrun.\n",
            "Note that --use_env is set by default in torchrun.\n",
            "If your script expects `--local_rank` argument to be set, please\n",
            "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
            "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
            "further instructions\n",
            "\n",
            "  FutureWarning,\n",
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
            "Load filenames from: ../data/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: ../data/birds/test/filenames.pickle (2933)\n",
            "Load from:  ../data/birds/captions_DAMSM.pickle\n",
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
            "Load filenames from: ../data/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: ../data/birds/test/filenames.pickle (2933)\n",
            "Load from:  ../data/birds/captions_DAMSM.pickle\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/inception.py:47: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Let's use 1 GPUs!\n",
            "{'CONFIG_NAME': 'bird',\n",
            " 'TEXT': {'CAPTIONS_PER_IMAGE': 10,\n",
            "          'DAMSM_NAME': '../data/birds/DAMSMencoder/text_encoder200.pth',\n",
            "          'EMBEDDING_DIM': 256,\n",
            "          'WORDS_NUM': 18},\n",
            " 'batch_size': 32,\n",
            " 'cfg_file': './cfg/bird.yml',\n",
            " 'ch_size': 3,\n",
            " 'checkpoint': './saved_models/bird/pretrained/state_epoch_1220.pth',\n",
            " 'cond_dim': 256,\n",
            " 'cuda': True,\n",
            " 'data_dir': '../data/birds',\n",
            " 'dataset_name': 'birds',\n",
            " 'device': device(type='cuda', index=0),\n",
            " 'example_captions': './example_captions/bird.txt',\n",
            " 'gen_interval': 1,\n",
            " 'gpu_id': 1,\n",
            " 'img_save_dir': '/content/gdrive/MyDrive/DF-GAN/code/imgs/bird/train/base_normal_bird_256_2022_08_21_08_32_11',\n",
            " 'imsize': 256,\n",
            " 'local_rank': 0,\n",
            " 'manual_seed': 100,\n",
            " 'max_epoch': 1301,\n",
            " 'model': 'base',\n",
            " 'model_save_file': '/content/gdrive/MyDrive/DF-GAN/code/saved_models/bird/base_normal_bird_256_2022_08_21_08_32_11',\n",
            " 'multi_gpus': True,\n",
            " 'nf': 32,\n",
            " 'npz_path': '../data/birds/npz/bird_val256_FIDK0.npz',\n",
            " 'num_workers': 1,\n",
            " 'random_sample': True,\n",
            " 'resume_epoch': 30,\n",
            " 'resume_model_path': './saved_models/bird/base_normal_bird_256_2022_08_20_02_30_54/',\n",
            " 'sample_times': 10,\n",
            " 'samples_save_dir': './samples/bird/',\n",
            " 'save_image': False,\n",
            " 'save_interval': 10,\n",
            " 'stamp': 'normal',\n",
            " 'state_epoch': 0,\n",
            " 'test_interval': 10,\n",
            " 'train': True,\n",
            " 'trunc_rate': 0.88,\n",
            " 'truncation': True,\n",
            " 'val_save_dir': './vals/bird/',\n",
            " 'vocab_size': 5450,\n",
            " 'z_dim': 100}\n",
            "Start Training\n",
            "  0% 0/276 [00:00<?, ?it/s][W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
            "Training Epoch [31/1301]: 100% 276/276 [50:10<00:00, 10.91s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:69: UserWarning: The parameter 'range' is deprecated since 0.12 and will be removed in 0.14. Please use 'value_range' instead.\n",
            "  \"The parameter 'range' is deprecated since 0.12 and will be removed in 0.14. \"\n",
            "The epoch 31 costs 3016.00s\n",
            "****************************************\n",
            "Training Epoch [32/1301]: 100% 276/276 [12:08<00:00,  2.64s/it]\n",
            "The epoch 32 costs 733.85s\n",
            "****************************************\n",
            "Training Epoch [33/1301]: 100% 276/276 [12:07<00:00,  2.63s/it]\n",
            "The epoch 33 costs 732.77s\n",
            "****************************************\n",
            "Training Epoch [34/1301]: 100% 276/276 [12:06<00:00,  2.63s/it]\n",
            "The epoch 34 costs 732.34s\n",
            "****************************************\n",
            "Training Epoch [35/1301]: 100% 276/276 [12:06<00:00,  2.63s/it]\n",
            "The epoch 35 costs 731.86s\n",
            "****************************************\n",
            "Training Epoch [36/1301]: 100% 276/276 [12:08<00:00,  2.64s/it]\n",
            "The epoch 36 costs 733.66s\n",
            "****************************************\n",
            "Training Epoch [37/1301]: 100% 276/276 [12:07<00:00,  2.64s/it]\n",
            "The epoch 37 costs 733.29s\n",
            "****************************************\n",
            "Training Epoch [38/1301]: 100% 276/276 [12:08<00:00,  2.64s/it]\n",
            "The epoch 38 costs 733.89s\n",
            "****************************************\n",
            "Training Epoch [39/1301]: 100% 276/276 [12:07<00:00,  2.63s/it]\n",
            "The epoch 39 costs 732.69s\n",
            "****************************************\n",
            "Training Epoch [40/1301]: 100% 276/276 [12:07<00:00,  2.64s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n",
            "100% 104M/104M [00:01<00:00, 56.1MB/s] \n",
            "  0% 0/910 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3722: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Evaluate Epoch [40/1301]: 100% 910/910 [22:05<00:00,  1.46s/it]\n",
            "The 40 epoch FID: 81.95\n",
            "The epoch 40 costs 2075.82s\n",
            "****************************************\n",
            "Training Epoch [41/1301]: 100% 276/276 [12:06<00:00,  2.63s/it]\n",
            "The epoch 41 costs 732.00s\n",
            "****************************************\n",
            "Training Epoch [42/1301]: 100% 276/276 [12:06<00:00,  2.63s/it]\n",
            "The epoch 42 costs 732.02s\n",
            "****************************************\n",
            "Training Epoch [43/1301]: 100% 276/276 [12:06<00:00,  2.63s/it]\n",
            "The epoch 43 costs 731.99s\n",
            "****************************************\n",
            "Training Epoch [44/1301]: 100% 276/276 [12:06<00:00,  2.63s/it]\n",
            "The epoch 44 costs 732.99s\n",
            "****************************************\n",
            "Training Epoch [45/1301]: 100% 276/276 [12:06<00:00,  2.63s/it]\n",
            "The epoch 45 costs 732.66s\n",
            "****************************************\n",
            "Training Epoch [46/1301]: 100% 276/276 [12:07<00:00,  2.64s/it]\n",
            "The epoch 46 costs 733.32s\n",
            "****************************************\n",
            "Training Epoch [47/1301]: 100% 276/276 [12:07<00:00,  2.64s/it]\n",
            "The epoch 47 costs 732.75s\n",
            "****************************************\n",
            "Training Epoch [48/1301]: 100% 276/276 [12:07<00:00,  2.63s/it]\n",
            "The epoch 48 costs 732.77s\n",
            "****************************************\n",
            "Training Epoch [49/1301]: 100% 276/276 [12:07<00:00,  2.63s/it]\n",
            "The epoch 49 costs 732.36s\n",
            "****************************************\n",
            "Training Epoch [50/1301]: 100% 276/276 [12:05<00:00,  2.63s/it]\n",
            "Evaluate Epoch [50/1301]: 100% 910/910 [06:05<00:00,  2.49it/s]\n",
            "The 50 epoch FID: 62.80\n",
            "The epoch 50 costs 1110.97s\n",
            "****************************************\n",
            "Training Epoch [51/1301]:  34% 93/276 [04:05<08:02,  2.64s/it]WARNING:torch.distributed.elastic.agent.server.api:Received 2 death signal, shutting down workers\n",
            "WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 456 closing signal SIGINT\n",
            "Traceback (most recent call last):\n",
            "  File \"src/train.py\", line 163, in <module>\n",
            "    main(args)\n",
            "  File \"src/train.py\", line 114, in main\n",
            "    train(train_dl, netG, netD, netC, text_encoder, optimizerG, optimizerD, args)\n",
            "  File \"/content/gdrive/MyDrive/DF-GAN/code/lib/modules.py\", line 66, in train\n",
            "WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 456 closing signal SIGTERM\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 709, in run\n",
            "    result = self._invoke_run(role)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 850, in _invoke_run\n",
            "    time.sleep(monitor_interval)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 60, in _terminate_process_handler\n",
            "    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\n",
            "torch.distributed.elastic.multiprocessing.api.SignalException: Process 443 got signal: 2\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 193, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 189, in main\n",
            "    launch(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 174, in launch\n",
            "    run(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/run.py\", line 755, in run\n",
            "    )(*cmd_args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launcher/api.py\", line 131, in __call__\n",
            "    return launch_agent(self._config, self._entrypoint, list(args))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launcher/api.py\", line 236, in launch_agent\n",
            "    result = agent.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/metrics/api.py\", line 125, in wrapper\n",
            "    result = f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 716, in run\n",
            "    self._shutdown(e.sigval)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py\", line 193, in _shutdown\n",
            "    self._pcontext.close(death_sig)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 330, in close\n",
            "    self._close(death_sig=death_sig, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 707, in _close\n",
            "    handler.proc.wait(time_to_wait)\n",
            "  File \"/usr/lib/python3.7/subprocess.py\", line 1019, in wait\n",
            "    return self._wait(timeout=timeout)\n",
            "  File \"/usr/lib/python3.7/subprocess.py\", line 1647, in _wait\n",
            "    time.sleep(delay)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 60, in _terminate_process_handler\n",
            "    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\n",
            "torch.distributed.elastic.multiprocessing.api.SignalException: Process 443 got signal: 2\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "import traceback\n",
        "try:\n",
        "  !bash scripts/train.sh ./cfg/bird.yml\n",
        "except:\n",
        "  print(traceback.format_exc())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYFEcnTbgult"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_MkmiACcsUx",
        "outputId": "85db7011-6ec8-4ab7-87d9-7cec68671427"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py:186: FutureWarning: The module torch.distributed.launch is deprecated\n",
            "and will be removed in future. Use torchrun.\n",
            "Note that --use_env is set by default in torchrun.\n",
            "If your script expects `--local_rank` argument to be set, please\n",
            "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
            "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
            "further instructions\n",
            "\n",
            "  FutureWarning,\n",
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
            "Load filenames from: ../data/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: ../data/birds/test/filenames.pickle (2933)\n",
            "Load from:  ../data/birds/captions_DAMSM.pickle\n",
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
            "Load filenames from: ../data/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: ../data/birds/test/filenames.pickle (2933)\n",
            "Load from:  ../data/birds/captions_DAMSM.pickle\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/inception.py:47: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Let's use 1 GPUs!\n",
            "{'CONFIG_NAME': 'bird',\n",
            " 'TEXT': {'CAPTIONS_PER_IMAGE': 10,\n",
            "          'DAMSM_NAME': '../data/birds/DAMSMencoder/text_encoder200.pth',\n",
            "          'EMBEDDING_DIM': 256,\n",
            "          'WORDS_NUM': 18},\n",
            " 'batch_size': 32,\n",
            " 'cfg_file': './cfg/bird.yml',\n",
            " 'ch_size': 3,\n",
            " 'checkpoint': './saved_models/bird/pretrained/state_epoch_1220.pth',\n",
            " 'cond_dim': 256,\n",
            " 'cuda': True,\n",
            " 'data_dir': '../data/birds',\n",
            " 'dataset_name': 'birds',\n",
            " 'device': device(type='cuda', index=0),\n",
            " 'example_captions': './example_captions/bird.txt',\n",
            " 'gen_interval': 1,\n",
            " 'gpu_id': 1,\n",
            " 'img_save_dir': '/content/gdrive/MyDrive/DF-GAN/code/imgs/bird/train/base_normal_bird_256_2022_10_11_05_34_14',\n",
            " 'imsize': 256,\n",
            " 'local_rank': 0,\n",
            " 'manual_seed': 100,\n",
            " 'max_epoch': 1301,\n",
            " 'model': 'base',\n",
            " 'model_save_file': '/content/gdrive/MyDrive/DF-GAN/code/saved_models/bird/base_normal_bird_256_2022_10_11_05_34_14',\n",
            " 'multi_gpus': True,\n",
            " 'nf': 32,\n",
            " 'npz_path': '../data/birds/npz/bird_val256_FIDK0.npz',\n",
            " 'num_workers': 1,\n",
            " 'random_sample': True,\n",
            " 'resume_epoch': 50,\n",
            " 'resume_model_path': './saved_models/bird/base_normal_bird_256_2022_08_21_08_32_11/',\n",
            " 'sample_times': 10,\n",
            " 'samples_save_dir': './samples/bird/',\n",
            " 'save_image': False,\n",
            " 'save_interval': 10,\n",
            " 'stamp': 'normal',\n",
            " 'state_epoch': 0,\n",
            " 'test_interval': 10,\n",
            " 'train': True,\n",
            " 'trunc_rate': 0.88,\n",
            " 'truncation': True,\n",
            " 'val_save_dir': './vals/bird/',\n",
            " 'vocab_size': 5450,\n",
            " 'z_dim': 100}\n",
            "Start Training\n",
            "  0% 0/276 [00:00<?, ?it/s][W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
            "Training Epoch [51/1301]: 100% 276/276 [56:52<00:00, 12.36s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:69: UserWarning: The parameter 'range' is deprecated since 0.12 and will be removed in 0.14. Please use 'value_range' instead.\n",
            "  \"The parameter 'range' is deprecated since 0.12 and will be removed in 0.14. \"\n",
            "The epoch 51 costs 3417.50s\n",
            "****************************************\n",
            "Training Epoch [52/1301]: 100% 276/276 [12:14<00:00,  2.66s/it]\n",
            "The epoch 52 costs 739.41s\n",
            "****************************************\n",
            "Training Epoch [53/1301]: 100% 276/276 [12:14<00:00,  2.66s/it]\n",
            "The epoch 53 costs 739.75s\n",
            "****************************************\n",
            "Training Epoch [54/1301]: 100% 276/276 [12:14<00:00,  2.66s/it]\n",
            "The epoch 54 costs 739.87s\n",
            "****************************************\n",
            "Training Epoch [55/1301]: 100% 276/276 [12:15<00:00,  2.66s/it]\n",
            "The epoch 55 costs 740.58s\n",
            "****************************************\n",
            "Training Epoch [56/1301]: 100% 276/276 [12:14<00:00,  2.66s/it]\n",
            "The epoch 56 costs 739.72s\n",
            "****************************************\n",
            "Training Epoch [57/1301]: 100% 276/276 [12:14<00:00,  2.66s/it]\n",
            "The epoch 57 costs 739.56s\n",
            "****************************************\n",
            "Training Epoch [58/1301]: 100% 276/276 [12:14<00:00,  2.66s/it]\n",
            "The epoch 58 costs 739.50s\n",
            "****************************************\n",
            "Training Epoch [59/1301]: 100% 276/276 [12:15<00:00,  2.66s/it]\n",
            "The epoch 59 costs 740.36s\n",
            "****************************************\n",
            "Training Epoch [60/1301]: 100% 276/276 [12:14<00:00,  2.66s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n",
            "100% 104M/104M [00:03<00:00, 35.4MB/s]\n",
            "  0% 0/910 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3722: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Evaluate Epoch [60/1301]: 100% 910/910 [23:24<00:00,  1.54s/it]\n",
            "The 60 epoch FID: 57.18\n",
            "The epoch 60 costs 2160.88s\n",
            "****************************************\n",
            "Training Epoch [61/1301]: 100% 276/276 [12:14<00:00,  2.66s/it]\n",
            "The epoch 61 costs 739.83s\n",
            "****************************************\n",
            "Training Epoch [62/1301]:  77% 213/276 [09:26<02:46,  2.65s/it]"
          ]
        }
      ],
      "source": [
        "import traceback\n",
        "try:\n",
        "  !bash scripts/train.sh ./cfg/bird.yml\n",
        "except:\n",
        "  print(traceback.format_exc())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrC8Z9f1DvP5",
        "outputId": "8c324de5-be2e-41ca-cf29-044169cac720"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py:186: FutureWarning: The module torch.distributed.launch is deprecated\n",
            "and will be removed in future. Use torchrun.\n",
            "Note that --use_env is set by default in torchrun.\n",
            "If your script expects `--local_rank` argument to be set, please\n",
            "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
            "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
            "further instructions\n",
            "\n",
            "  FutureWarning,\n",
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
            "Load filenames from: ../data/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: ../data/birds/test/filenames.pickle (2933)\n",
            "Load from:  ../data/birds/captions_DAMSM.pickle\n",
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
            "Load filenames from: ../data/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: ../data/birds/test/filenames.pickle (2933)\n",
            "Load from:  ../data/birds/captions_DAMSM.pickle\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/inception.py:47: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Let's use 1 GPUs!\n",
            "{'CONFIG_NAME': 'bird',\n",
            " 'TEXT': {'CAPTIONS_PER_IMAGE': 10,\n",
            "          'DAMSM_NAME': '../data/birds/DAMSMencoder/text_encoder200.pth',\n",
            "          'EMBEDDING_DIM': 256,\n",
            "          'WORDS_NUM': 18},\n",
            " 'batch_size': 32,\n",
            " 'cfg_file': './cfg/bird.yml',\n",
            " 'ch_size': 3,\n",
            " 'checkpoint': './saved_models/bird/pretrained/state_epoch_1220.pth',\n",
            " 'cond_dim': 256,\n",
            " 'cuda': True,\n",
            " 'data_dir': '../data/birds',\n",
            " 'dataset_name': 'birds',\n",
            " 'device': device(type='cuda', index=0),\n",
            " 'example_captions': './example_captions/bird.txt',\n",
            " 'gen_interval': 1,\n",
            " 'gpu_id': 1,\n",
            " 'img_save_dir': '/content/gdrive/MyDrive/DF-GAN/code/imgs/bird/train/base_normal_bird_256_2022_10_15_07_02_51',\n",
            " 'imsize': 256,\n",
            " 'local_rank': 0,\n",
            " 'manual_seed': 100,\n",
            " 'max_epoch': 1301,\n",
            " 'model': 'base',\n",
            " 'model_save_file': '/content/gdrive/MyDrive/DF-GAN/code/saved_models/bird/base_normal_bird_256_2022_10_15_07_02_51',\n",
            " 'multi_gpus': True,\n",
            " 'nf': 32,\n",
            " 'npz_path': '../data/birds/npz/bird_val256_FIDK0.npz',\n",
            " 'num_workers': 1,\n",
            " 'random_sample': True,\n",
            " 'resume_epoch': 60,\n",
            " 'resume_model_path': './saved_models/bird/base_normal_bird_256_2022_10_11_05_34_14/',\n",
            " 'sample_times': 10,\n",
            " 'samples_save_dir': './samples/bird/',\n",
            " 'save_image': False,\n",
            " 'save_interval': 10,\n",
            " 'stamp': 'normal',\n",
            " 'state_epoch': 0,\n",
            " 'test_interval': 10,\n",
            " 'train': True,\n",
            " 'trunc_rate': 0.88,\n",
            " 'truncation': True,\n",
            " 'val_save_dir': './vals/bird/',\n",
            " 'vocab_size': 5450,\n",
            " 'z_dim': 100}\n",
            "Start Training\n",
            "  0% 0/276 [00:00<?, ?it/s][W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
            "Training Epoch [61/1301]: 100% 276/276 [1:46:23<00:00, 23.13s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:69: UserWarning: The parameter 'range' is deprecated since 0.12 and will be removed in 0.14. Please use 'value_range' instead.\n",
            "  \"The parameter 'range' is deprecated since 0.12 and will be removed in 0.14. \"\n",
            "The epoch 61 costs 6388.33s\n",
            "****************************************\n",
            "Training Epoch [62/1301]: 100% 276/276 [12:00<00:00,  2.61s/it]\n",
            "The epoch 62 costs 725.80s\n",
            "****************************************\n",
            "Training Epoch [63/1301]: 100% 276/276 [11:59<00:00,  2.61s/it]\n",
            "The epoch 63 costs 724.56s\n",
            "****************************************\n",
            "Training Epoch [64/1301]: 100% 276/276 [11:59<00:00,  2.61s/it]\n",
            "The epoch 64 costs 724.20s\n",
            "****************************************\n",
            "Training Epoch [65/1301]: 100% 276/276 [11:59<00:00,  2.61s/it]\n",
            "The epoch 65 costs 724.68s\n",
            "****************************************\n",
            "Training Epoch [66/1301]: 100% 276/276 [11:59<00:00,  2.61s/it]\n",
            "The epoch 66 costs 725.26s\n",
            "****************************************\n",
            "Training Epoch [67/1301]: 100% 276/276 [11:58<00:00,  2.60s/it]\n",
            "The epoch 67 costs 723.56s\n",
            "****************************************\n",
            "Training Epoch [68/1301]: 100% 276/276 [11:59<00:00,  2.61s/it]\n",
            "The epoch 68 costs 724.77s\n",
            "****************************************\n",
            "Training Epoch [69/1301]: 100% 276/276 [11:59<00:00,  2.61s/it]\n",
            "The epoch 69 costs 726.05s\n",
            "****************************************\n",
            "Training Epoch [70/1301]: 100% 276/276 [11:59<00:00,  2.61s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n",
            "100% 104M/104M [00:04<00:00, 26.1MB/s]\n",
            "  0% 0/910 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3722: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Evaluate Epoch [70/1301]: 100% 910/910 [40:09<00:00,  2.65s/it]\n",
            "The 70 epoch FID: 54.16\n",
            "The epoch 70 costs 3152.15s\n",
            "****************************************\n",
            "Training Epoch [71/1301]: 100% 276/276 [11:58<00:00,  2.60s/it]\n",
            "The epoch 71 costs 723.63s\n",
            "****************************************\n",
            "Training Epoch [72/1301]: 100% 276/276 [11:59<00:00,  2.61s/it]\n",
            "The epoch 72 costs 724.99s\n",
            "****************************************\n",
            "Training Epoch [73/1301]: 100% 276/276 [11:59<00:00,  2.61s/it]\n",
            "The epoch 73 costs 724.94s\n",
            "****************************************\n",
            "Training Epoch [74/1301]: 100% 276/276 [11:59<00:00,  2.61s/it]\n",
            "The epoch 74 costs 724.96s\n",
            "****************************************\n",
            "Training Epoch [75/1301]: 100% 276/276 [11:59<00:00,  2.61s/it]\n",
            "The epoch 75 costs 724.97s\n",
            "****************************************\n",
            "Training Epoch [76/1301]: 100% 276/276 [11:58<00:00,  2.60s/it]\n",
            "The epoch 76 costs 724.16s\n",
            "****************************************\n",
            "Training Epoch [77/1301]:  71% 196/276 [08:30<03:27,  2.60s/it]"
          ]
        }
      ],
      "source": [
        "import traceback\n",
        "try:\n",
        "  !bash scripts/train.sh ./cfg/bird.yml\n",
        "except:\n",
        "  print(traceback.format_exc())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHUh9N2iDvbX",
        "outputId": "8a45a6ce-3788-4afb-ac1b-536acbf6670b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py:186: FutureWarning: The module torch.distributed.launch is deprecated\n",
            "and will be removed in future. Use torchrun.\n",
            "Note that --use_env is set by default in torchrun.\n",
            "If your script expects `--local_rank` argument to be set, please\n",
            "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
            "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
            "further instructions\n",
            "\n",
            "  FutureWarning,\n",
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
            "Load filenames from: ../data/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: ../data/birds/test/filenames.pickle (2933)\n",
            "Load from:  ../data/birds/captions_DAMSM.pickle\n",
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
            "Load filenames from: ../data/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: ../data/birds/test/filenames.pickle (2933)\n",
            "Load from:  ../data/birds/captions_DAMSM.pickle\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/inception.py:47: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Let's use 1 GPUs!\n",
            "{'CONFIG_NAME': 'bird',\n",
            " 'TEXT': {'CAPTIONS_PER_IMAGE': 10,\n",
            "          'DAMSM_NAME': '../data/birds/DAMSMencoder/text_encoder200.pth',\n",
            "          'EMBEDDING_DIM': 256,\n",
            "          'WORDS_NUM': 18},\n",
            " 'batch_size': 32,\n",
            " 'cfg_file': './cfg/bird.yml',\n",
            " 'ch_size': 3,\n",
            " 'checkpoint': './saved_models/bird/pretrained/state_epoch_1220.pth',\n",
            " 'cond_dim': 256,\n",
            " 'cuda': True,\n",
            " 'data_dir': '../data/birds',\n",
            " 'dataset_name': 'birds',\n",
            " 'device': device(type='cuda', index=0),\n",
            " 'example_captions': './example_captions/bird.txt',\n",
            " 'gen_interval': 1,\n",
            " 'gpu_id': 1,\n",
            " 'img_save_dir': '/content/gdrive/MyDrive/DF-GAN/code/imgs/bird/train/base_normal_bird_256_2022_10_25_07_54_13',\n",
            " 'imsize': 256,\n",
            " 'local_rank': 0,\n",
            " 'manual_seed': 100,\n",
            " 'max_epoch': 1301,\n",
            " 'model': 'base',\n",
            " 'model_save_file': '/content/gdrive/MyDrive/DF-GAN/code/saved_models/bird/base_normal_bird_256_2022_10_25_07_54_13',\n",
            " 'multi_gpus': True,\n",
            " 'nf': 32,\n",
            " 'npz_path': '../data/birds/npz/bird_val256_FIDK0.npz',\n",
            " 'num_workers': 1,\n",
            " 'random_sample': True,\n",
            " 'resume_epoch': 70,\n",
            " 'resume_model_path': './saved_models/bird/base_normal_bird_256_2022_10_15_07_02_51/',\n",
            " 'sample_times': 10,\n",
            " 'samples_save_dir': './samples/bird/',\n",
            " 'save_image': False,\n",
            " 'save_interval': 10,\n",
            " 'stamp': 'normal',\n",
            " 'state_epoch': 0,\n",
            " 'test_interval': 10,\n",
            " 'train': True,\n",
            " 'trunc_rate': 0.88,\n",
            " 'truncation': True,\n",
            " 'val_save_dir': './vals/bird/',\n",
            " 'vocab_size': 5450,\n",
            " 'z_dim': 100}\n",
            "Start Training\n",
            "  0% 0/276 [00:00<?, ?it/s][W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
            "Training Epoch [71/1301]: 100% 276/276 [1:46:45<00:00, 23.21s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:69: UserWarning: The parameter 'range' is deprecated since 0.12 and will be removed in 0.14. Please use 'value_range' instead.\n",
            "  \"The parameter 'range' is deprecated since 0.12 and will be removed in 0.14. \"\n",
            "The epoch 71 costs 6411.08s\n",
            "****************************************\n",
            "Training Epoch [72/1301]: 100% 276/276 [11:54<00:00,  2.59s/it]\n",
            "The epoch 72 costs 719.96s\n",
            "****************************************\n",
            "Training Epoch [73/1301]: 100% 276/276 [11:54<00:00,  2.59s/it]\n",
            "The epoch 73 costs 720.29s\n",
            "****************************************\n",
            "Training Epoch [74/1301]: 100% 276/276 [11:55<00:00,  2.59s/it]\n",
            "The epoch 74 costs 720.35s\n",
            "****************************************\n",
            "Training Epoch [75/1301]: 100% 276/276 [11:57<00:00,  2.60s/it]\n",
            "The epoch 75 costs 722.33s\n",
            "****************************************\n",
            "Training Epoch [76/1301]: 100% 276/276 [11:56<00:00,  2.60s/it]\n",
            "The epoch 76 costs 721.94s\n",
            "****************************************\n",
            "Training Epoch [77/1301]: 100% 276/276 [11:55<00:00,  2.59s/it]\n",
            "The epoch 77 costs 720.41s\n",
            "****************************************\n",
            "Training Epoch [78/1301]: 100% 276/276 [11:55<00:00,  2.59s/it]\n",
            "The epoch 78 costs 720.94s\n",
            "****************************************\n",
            "Training Epoch [79/1301]: 100% 276/276 [11:56<00:00,  2.59s/it]\n",
            "The epoch 79 costs 721.28s\n",
            "****************************************\n",
            "Training Epoch [80/1301]: 100% 276/276 [11:55<00:00,  2.59s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n",
            "100% 104M/104M [00:04<00:00, 23.9MB/s]\n",
            "  0% 0/910 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3722: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Evaluate Epoch [80/1301]:   3% 26/910 [09:33<5:39:49, 23.06s/it]"
          ]
        }
      ],
      "source": [
        "import traceback\n",
        "try:\n",
        "  !bash scripts/train.sh ./cfg/bird.yml\n",
        "except:\n",
        "  print(traceback.format_exc()) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFkhKx_igxsY",
        "outputId": "da410fec-08d1-4d10-9cea-20057c79bf12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py:186: FutureWarning: The module torch.distributed.launch is deprecated\n",
            "and will be removed in future. Use torchrun.\n",
            "Note that --use_env is set by default in torchrun.\n",
            "If your script expects `--local_rank` argument to be set, please\n",
            "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
            "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
            "further instructions\n",
            "\n",
            "  FutureWarning,\n",
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
            "Load filenames from: ../data/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: ../data/birds/test/filenames.pickle (2933)\n",
            "Load from:  ../data/birds/captions_DAMSM.pickle\n",
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
            "Load filenames from: ../data/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: ../data/birds/test/filenames.pickle (2933)\n",
            "Load from:  ../data/birds/captions_DAMSM.pickle\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/inception.py:47: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Let's use 1 GPUs!\n",
            "{'CONFIG_NAME': 'bird',\n",
            " 'TEXT': {'CAPTIONS_PER_IMAGE': 10,\n",
            "          'DAMSM_NAME': '../data/birds/DAMSMencoder/text_encoder200.pth',\n",
            "          'EMBEDDING_DIM': 256,\n",
            "          'WORDS_NUM': 18},\n",
            " 'batch_size': 32,\n",
            " 'cfg_file': './cfg/bird.yml',\n",
            " 'ch_size': 3,\n",
            " 'checkpoint': './saved_models/bird/pretrained/state_epoch_1220.pth',\n",
            " 'cond_dim': 256,\n",
            " 'cuda': True,\n",
            " 'data_dir': '../data/birds',\n",
            " 'dataset_name': 'birds',\n",
            " 'device': device(type='cuda', index=0),\n",
            " 'example_captions': './example_captions/bird.txt',\n",
            " 'gen_interval': 1,\n",
            " 'gpu_id': 1,\n",
            " 'img_save_dir': '/content/gdrive/MyDrive/DF-GAN/code/imgs/bird/train/base_normal_bird_256_2022_10_26_08_18_22',\n",
            " 'imsize': 256,\n",
            " 'local_rank': 0,\n",
            " 'manual_seed': 100,\n",
            " 'max_epoch': 1301,\n",
            " 'model': 'base',\n",
            " 'model_save_file': '/content/gdrive/MyDrive/DF-GAN/code/saved_models/bird/base_normal_bird_256_2022_10_26_08_18_22',\n",
            " 'multi_gpus': True,\n",
            " 'nf': 32,\n",
            " 'npz_path': '../data/birds/npz/bird_val256_FIDK0.npz',\n",
            " 'num_workers': 1,\n",
            " 'random_sample': True,\n",
            " 'resume_epoch': 80,\n",
            " 'resume_model_path': './saved_models/bird/base_normal_bird_256_2022_10_25_07_54_13/',\n",
            " 'sample_times': 10,\n",
            " 'samples_save_dir': './samples/bird/',\n",
            " 'save_image': False,\n",
            " 'save_interval': 10,\n",
            " 'stamp': 'normal',\n",
            " 'state_epoch': 0,\n",
            " 'test_interval': 10,\n",
            " 'train': True,\n",
            " 'trunc_rate': 0.88,\n",
            " 'truncation': True,\n",
            " 'val_save_dir': './vals/bird/',\n",
            " 'vocab_size': 5450,\n",
            " 'z_dim': 100}\n",
            "Start Training\n",
            "  0% 0/276 [00:00<?, ?it/s][W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
            "Training Epoch [81/1301]: 100% 276/276 [1:47:09<00:00, 23.30s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:69: UserWarning: The parameter 'range' is deprecated since 0.12 and will be removed in 0.14. Please use 'value_range' instead.\n",
            "  \"The parameter 'range' is deprecated since 0.12 and will be removed in 0.14. \"\n",
            "The epoch 81 costs 6434.89s\n",
            "****************************************\n",
            "Training Epoch [82/1301]: 100% 276/276 [12:07<00:00,  2.63s/it]\n",
            "The epoch 82 costs 732.35s\n",
            "****************************************\n",
            "Training Epoch [83/1301]: 100% 276/276 [12:08<00:00,  2.64s/it]\n",
            "The epoch 83 costs 733.01s\n",
            "****************************************\n",
            "Training Epoch [84/1301]: 100% 276/276 [12:08<00:00,  2.64s/it]\n",
            "The epoch 84 costs 733.38s\n",
            "****************************************\n",
            "Training Epoch [85/1301]: 100% 276/276 [12:07<00:00,  2.64s/it]\n",
            "The epoch 85 costs 732.56s\n",
            "****************************************\n",
            "Training Epoch [86/1301]: 100% 276/276 [12:05<00:00,  2.63s/it]\n",
            "The epoch 86 costs 730.95s\n",
            "****************************************\n",
            "Training Epoch [87/1301]: 100% 276/276 [12:05<00:00,  2.63s/it]\n",
            "The epoch 87 costs 730.71s\n",
            "****************************************\n",
            "Training Epoch [88/1301]: 100% 276/276 [12:06<00:00,  2.63s/it]\n",
            "The epoch 88 costs 731.66s\n",
            "****************************************\n",
            "Training Epoch [89/1301]: 100% 276/276 [12:05<00:00,  2.63s/it]\n",
            "The epoch 89 costs 730.67s\n",
            "****************************************\n",
            "Training Epoch [90/1301]: 100% 276/276 [12:07<00:00,  2.63s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n",
            "100% 104M/104M [00:04<00:00, 22.6MB/s]\n",
            "  0% 0/910 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3722: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Evaluate Epoch [90/1301]:   2% 18/910 [06:47<5:47:23, 23.37s/it]Traceback (most recent call last):\n",
            "  File \"src/train.py\", line 163, in <module>\n",
            "WARNING:torch.distributed.elastic.agent.server.api:Received 2 death signal, shutting down workers\n",
            "WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 380 closing signal SIGINT\n",
            "  File \"src/train.py\", line 127, in main\n",
            "    args.sample_times, args.z_dim, args.batch_size, args.truncation, args.trunc_rate)\n",
            "  File \"/content/gdrive/MyDrive/DF-GAN/code/lib/modules.py\", line 133, in test\n",
            "    times, z_dim, batch_size, truncation, trunc_rate)\n",
            "  File \"/content/gdrive/MyDrive/DF-GAN/code/lib/modules.py\", line 160, in calculate_fid\n",
            "    for i, data in enumerate(dataloader):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 681, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1359, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1325, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1163, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 104, in get\n",
            "    if not self._poll(timeout):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 257, in poll\n",
            "    return self._poll(timeout)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 414, in _poll\n",
            "    r = wait([self], timeout)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 921, in wait\n",
            "    ready = selector.select(timeout)\n",
            "  File \"/usr/lib/python3.7/selectors.py\", line 415, in select\n",
            "    fd_event_list = self._selector.poll(timeout)\n",
            "KeyboardInterrupt\n",
            "Evaluate Epoch [90/1301]:   2% 18/910 [06:59<5:46:18, 23.29s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 193, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 189, in main\n",
            "    launch(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 174, in launch\n",
            "    run(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/run.py\", line 755, in run\n",
            "    )(*cmd_args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launcher/api.py\", line 131, in __call__\n",
            "    return launch_agent(self._config, self._entrypoint, list(args))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launcher/api.py\", line 236, in launch_agent\n",
            "    result = agent.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/metrics/api.py\", line 125, in wrapper\n",
            "    result = f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 709, in run\n",
            "    result = self._invoke_run(role)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 850, in _invoke_run\n",
            "    time.sleep(monitor_interval)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 60, in _terminate_process_handler\n",
            "    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\n",
            "torch.distributed.elastic.multiprocessing.api.SignalException: Process 363 got signal: 2\n"
          ]
        }
      ],
      "source": [
        "import traceback\n",
        "try:\n",
        "  !bash scripts/train.sh ./cfg/bird.yml\n",
        "except:\n",
        "  print(traceback.format_exc())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLLQOHI_h_rt",
        "outputId": "43d4393a-55c7-415c-ee3a-afcc9c3d0511"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py:186: FutureWarning: The module torch.distributed.launch is deprecated\n",
            "and will be removed in future. Use torchrun.\n",
            "Note that --use_env is set by default in torchrun.\n",
            "If your script expects `--local_rank` argument to be set, please\n",
            "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
            "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
            "further instructions\n",
            "\n",
            "  FutureWarning,\n",
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
            "Load filenames from: ../data/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: ../data/birds/test/filenames.pickle (2933)\n",
            "Load from:  ../data/birds/captions_DAMSM.pickle\n",
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
            "Load filenames from: ../data/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: ../data/birds/test/filenames.pickle (2933)\n",
            "Load from:  ../data/birds/captions_DAMSM.pickle\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/inception.py:47: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Let's use 1 GPUs!\n",
            "{'CONFIG_NAME': 'bird',\n",
            " 'TEXT': {'CAPTIONS_PER_IMAGE': 10,\n",
            "          'DAMSM_NAME': '../data/birds/DAMSMencoder/text_encoder200.pth',\n",
            "          'EMBEDDING_DIM': 256,\n",
            "          'WORDS_NUM': 18},\n",
            " 'batch_size': 32,\n",
            " 'cfg_file': './cfg/bird.yml',\n",
            " 'ch_size': 3,\n",
            " 'checkpoint': './saved_models/bird/pretrained/state_epoch_1220.pth',\n",
            " 'cond_dim': 256,\n",
            " 'cuda': True,\n",
            " 'data_dir': '../data/birds',\n",
            " 'dataset_name': 'birds',\n",
            " 'device': device(type='cuda', index=0),\n",
            " 'example_captions': './example_captions/bird.txt',\n",
            " 'gen_interval': 1,\n",
            " 'gpu_id': 1,\n",
            " 'img_save_dir': '/content/gdrive/MyDrive/DF-GAN/code/imgs/bird/train/base_normal_bird_256_2022_10_28_07_16_57',\n",
            " 'imsize': 256,\n",
            " 'local_rank': 0,\n",
            " 'manual_seed': 100,\n",
            " 'max_epoch': 1301,\n",
            " 'model': 'base',\n",
            " 'model_save_file': '/content/gdrive/MyDrive/DF-GAN/code/saved_models/bird/base_normal_bird_256_2022_10_28_07_16_57',\n",
            " 'multi_gpus': True,\n",
            " 'nf': 32,\n",
            " 'npz_path': '../data/birds/npz/bird_val256_FIDK0.npz',\n",
            " 'num_workers': 1,\n",
            " 'random_sample': True,\n",
            " 'resume_epoch': 90,\n",
            " 'resume_model_path': './saved_models/bird/base_normal_bird_256_2022_10_26_08_18_22/',\n",
            " 'sample_times': 10,\n",
            " 'samples_save_dir': './samples/bird/',\n",
            " 'save_image': False,\n",
            " 'save_interval': 10,\n",
            " 'stamp': 'normal',\n",
            " 'state_epoch': 0,\n",
            " 'test_interval': 10,\n",
            " 'train': True,\n",
            " 'trunc_rate': 0.88,\n",
            " 'truncation': True,\n",
            " 'val_save_dir': './vals/bird/',\n",
            " 'vocab_size': 5450,\n",
            " 'z_dim': 100}\n",
            "Start Training\n",
            "  0% 0/276 [00:00<?, ?it/s][W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
            "Training Epoch [91/1301]: 100% 276/276 [40:48<00:00,  8.87s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:69: UserWarning: The parameter 'range' is deprecated since 0.12 and will be removed in 0.14. Please use 'value_range' instead.\n",
            "  \"The parameter 'range' is deprecated since 0.12 and will be removed in 0.14. \"\n",
            "The epoch 91 costs 2454.05s\n",
            "****************************************\n",
            "Training Epoch [92/1301]: 100% 276/276 [12:14<00:00,  2.66s/it]\n",
            "The epoch 92 costs 739.94s\n",
            "****************************************\n",
            "Training Epoch [93/1301]: 100% 276/276 [12:13<00:00,  2.66s/it]\n",
            "The epoch 93 costs 738.30s\n",
            "****************************************\n",
            "Training Epoch [94/1301]: 100% 276/276 [12:14<00:00,  2.66s/it]\n",
            "The epoch 94 costs 739.21s\n",
            "****************************************\n",
            "Training Epoch [95/1301]: 100% 276/276 [12:12<00:00,  2.65s/it]\n",
            "The epoch 95 costs 737.70s\n",
            "****************************************\n",
            "Training Epoch [96/1301]: 100% 276/276 [12:14<00:00,  2.66s/it]\n",
            "The epoch 96 costs 739.61s\n",
            "****************************************\n",
            "Training Epoch [97/1301]: 100% 276/276 [12:12<00:00,  2.65s/it]\n",
            "The epoch 97 costs 737.77s\n",
            "****************************************\n",
            "Training Epoch [98/1301]: 100% 276/276 [12:13<00:00,  2.66s/it]\n",
            "The epoch 98 costs 738.44s\n",
            "****************************************\n",
            "Training Epoch [99/1301]: 100% 276/276 [12:12<00:00,  2.65s/it]\n",
            "The epoch 99 costs 738.27s\n",
            "****************************************\n",
            "Training Epoch [100/1301]: 100% 276/276 [12:13<00:00,  2.66s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n",
            "100% 104M/104M [00:03<00:00, 28.5MB/s] \n",
            "  0% 0/910 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3722: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Evaluate Epoch [100/1301]: 100% 910/910 [18:30<00:00,  1.22s/it]\n",
            "The 100 epoch FID: 37.72\n",
            "The epoch 100 costs 1865.91s\n",
            "****************************************\n",
            "Training Epoch [101/1301]: 100% 276/276 [12:13<00:00,  2.66s/it]\n",
            "The epoch 101 costs 738.90s\n",
            "****************************************\n",
            "Training Epoch [102/1301]: 100% 276/276 [12:14<00:00,  2.66s/it]\n",
            "The epoch 102 costs 739.57s\n",
            "****************************************\n",
            "Training Epoch [103/1301]: 100% 276/276 [12:14<00:00,  2.66s/it]\n",
            "The epoch 103 costs 739.22s\n",
            "****************************************\n",
            "Training Epoch [104/1301]: 100% 276/276 [12:13<00:00,  2.66s/it]\n",
            "The epoch 104 costs 738.46s\n",
            "****************************************\n",
            "Training Epoch [105/1301]:  98% 270/276 [11:58<00:15,  2.63s/it]"
          ]
        }
      ],
      "source": [
        "import traceback\n",
        "try:\n",
        "  !bash scripts/train.sh ./cfg/bird.yml\n",
        "except:\n",
        "  print(traceback.format_exc())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRmZsBJdFrZS",
        "outputId": "75cb1ca5-03e6-49c7-9d37-8db2364f95f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py:186: FutureWarning: The module torch.distributed.launch is deprecated\n",
            "and will be removed in future. Use torchrun.\n",
            "Note that --use_env is set by default in torchrun.\n",
            "If your script expects `--local_rank` argument to be set, please\n",
            "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
            "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
            "further instructions\n",
            "\n",
            "  FutureWarning,\n",
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
            "Load filenames from: ../data/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: ../data/birds/test/filenames.pickle (2933)\n",
            "Load from:  ../data/birds/captions_DAMSM.pickle\n",
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
            "Load filenames from: ../data/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: ../data/birds/test/filenames.pickle (2933)\n",
            "Load from:  ../data/birds/captions_DAMSM.pickle\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/inception.py:47: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Let's use 1 GPUs!\n",
            "{'CONFIG_NAME': 'bird',\n",
            " 'TEXT': {'CAPTIONS_PER_IMAGE': 10,\n",
            "          'DAMSM_NAME': '../data/birds/DAMSMencoder/text_encoder200.pth',\n",
            "          'EMBEDDING_DIM': 256,\n",
            "          'WORDS_NUM': 18},\n",
            " 'batch_size': 32,\n",
            " 'cfg_file': './cfg/bird.yml',\n",
            " 'ch_size': 3,\n",
            " 'checkpoint': './saved_models/bird/pretrained/state_epoch_1220.pth',\n",
            " 'cond_dim': 256,\n",
            " 'cuda': True,\n",
            " 'data_dir': '../data/birds',\n",
            " 'dataset_name': 'birds',\n",
            " 'device': device(type='cuda', index=0),\n",
            " 'example_captions': './example_captions/bird.txt',\n",
            " 'gen_interval': 1,\n",
            " 'gpu_id': 1,\n",
            " 'img_save_dir': '/content/gdrive/MyDrive/DF-GAN/code/imgs/bird/train/base_normal_bird_256_2022_11_10_12_52_19',\n",
            " 'imsize': 256,\n",
            " 'local_rank': 0,\n",
            " 'manual_seed': 100,\n",
            " 'max_epoch': 1301,\n",
            " 'model': 'base',\n",
            " 'model_save_file': '/content/gdrive/MyDrive/DF-GAN/code/saved_models/bird/base_normal_bird_256_2022_11_10_12_52_19',\n",
            " 'multi_gpus': True,\n",
            " 'nf': 32,\n",
            " 'npz_path': '../data/birds/npz/bird_val256_FIDK0.npz',\n",
            " 'num_workers': 1,\n",
            " 'random_sample': True,\n",
            " 'resume_epoch': 100,\n",
            " 'resume_model_path': './saved_models/bird/base_normal_bird_256_2022_10_28_07_16_57/',\n",
            " 'sample_times': 10,\n",
            " 'samples_save_dir': './samples/bird/',\n",
            " 'save_image': False,\n",
            " 'save_interval': 10,\n",
            " 'stamp': 'normal',\n",
            " 'state_epoch': 0,\n",
            " 'test_interval': 10,\n",
            " 'train': True,\n",
            " 'trunc_rate': 0.88,\n",
            " 'truncation': True,\n",
            " 'val_save_dir': './vals/bird/',\n",
            " 'vocab_size': 5450,\n",
            " 'z_dim': 100}\n",
            "Start Training\n",
            "  0% 0/276 [00:00<?, ?it/s][W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
            "Training Epoch [101/1301]: 100% 276/276 [56:58<00:00, 12.38s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:69: UserWarning: The parameter 'range' is deprecated since 0.12 and will be removed in 0.14. Please use 'value_range' instead.\n",
            "  \"The parameter 'range' is deprecated since 0.12 and will be removed in 0.14. \"\n",
            "The epoch 101 costs 3423.69s\n",
            "****************************************\n",
            "Training Epoch [102/1301]: 100% 276/276 [11:57<00:00,  2.60s/it]\n",
            "The epoch 102 costs 722.81s\n",
            "****************************************\n",
            "Training Epoch [103/1301]: 100% 276/276 [11:56<00:00,  2.60s/it]\n",
            "The epoch 103 costs 722.30s\n",
            "****************************************\n",
            "Training Epoch [104/1301]: 100% 276/276 [11:58<00:00,  2.60s/it]\n",
            "The epoch 104 costs 724.17s\n",
            "****************************************\n",
            "Training Epoch [105/1301]: 100% 276/276 [11:58<00:00,  2.60s/it]\n",
            "The epoch 105 costs 724.07s\n",
            "****************************************\n",
            "Training Epoch [106/1301]: 100% 276/276 [11:56<00:00,  2.60s/it]\n",
            "The epoch 106 costs 722.41s\n",
            "****************************************\n",
            "Training Epoch [107/1301]: 100% 276/276 [11:56<00:00,  2.60s/it]\n",
            "The epoch 107 costs 722.38s\n",
            "****************************************\n",
            "Training Epoch [108/1301]: 100% 276/276 [11:56<00:00,  2.59s/it]\n",
            "The epoch 108 costs 721.73s\n",
            "****************************************\n",
            "Training Epoch [109/1301]: 100% 276/276 [11:56<00:00,  2.59s/it]\n",
            "The epoch 109 costs 721.52s\n",
            "****************************************\n",
            "Training Epoch [110/1301]: 100% 276/276 [11:56<00:00,  2.60s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n",
            "100% 104M/104M [00:01<00:00, 106MB/s] \n",
            "  0% 0/910 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3722: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Evaluate Epoch [110/1301]: 100% 910/910 [23:29<00:00,  1.55s/it]\n",
            "The 110 epoch FID: 45.07\n",
            "The epoch 110 costs 2147.63s\n",
            "****************************************\n",
            "Training Epoch [111/1301]:  92% 253/276 [10:57<00:59,  2.58s/it]"
          ]
        }
      ],
      "source": [
        "import traceback\n",
        "try:\n",
        "  !bash scripts/train.sh ./cfg/bird.yml\n",
        "except:\n",
        "  print(traceback.format_exc()) "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "DFstenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0 (tags/v3.9.0:9cf6752, Oct  5 2020, 15:34:40) [MSC v.1927 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "8ba17319f1ede631891b0d7dd562da5122b358b3c4d74ac8a0a07d8d7af2003c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
